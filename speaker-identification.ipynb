{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-24T08:11:44.544068Z","iopub.status.busy":"2022-07-24T08:11:44.543736Z","iopub.status.idle":"2022-07-24T08:11:48.831735Z","shell.execute_reply":"2022-07-24T08:11:48.831000Z","shell.execute_reply.started":"2022-07-24T08:11:44.543996Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import os\n","from os.path import isfile, join\n","import numpy as np\n","import shutil\n","from tensorflow import keras\n","from pathlib import Path\n","from IPython.display import display, Audio\n","import subprocess"]},{"cell_type":"markdown","metadata":{},"source":["Copy dataset to arrange audio and noise in different folders"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:11:48.833510Z","iopub.status.busy":"2022-07-24T08:11:48.833279Z","iopub.status.idle":"2022-07-24T08:12:14.481708Z","shell.execute_reply":"2022-07-24T08:12:14.480782Z","shell.execute_reply.started":"2022-07-24T08:11:48.833468Z"},"trusted":true},"outputs":[],"source":["!cp -r \"../input/speaker-recognition-dataset\" ./"]},{"cell_type":"markdown","metadata":{},"source":["Get the data directories"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.485309Z","iopub.status.busy":"2022-07-24T08:12:14.485068Z","iopub.status.idle":"2022-07-24T08:12:14.490889Z","shell.execute_reply":"2022-07-24T08:12:14.490202Z","shell.execute_reply.started":"2022-07-24T08:12:14.485281Z"},"trusted":true},"outputs":[],"source":["\n","data_directory = \"./speaker-recognition-dataset/16000_pcm_speeches\"\n","audio_folder = \"audio\"\n","noise_folder = \"noise\"\n","\n","audio_path = os.path.join(data_directory, audio_folder)\n","noise_path = os.path.join(data_directory, noise_folder)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.493844Z","iopub.status.busy":"2022-07-24T08:12:14.493406Z","iopub.status.idle":"2022-07-24T08:12:14.505280Z","shell.execute_reply":"2022-07-24T08:12:14.504194Z","shell.execute_reply.started":"2022-07-24T08:12:14.493806Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'./speaker-recognition-dataset/16000_pcm_speeches/audio'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["audio_path"]},{"cell_type":"markdown","metadata":{},"source":["set all the parameters for training and other purposes"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.508557Z","iopub.status.busy":"2022-07-24T08:12:14.508303Z","iopub.status.idle":"2022-07-24T08:12:14.513162Z","shell.execute_reply":"2022-07-24T08:12:14.512396Z","shell.execute_reply.started":"2022-07-24T08:12:14.508524Z"},"trusted":true},"outputs":[],"source":["valid_split = 0.1\n","\n","shuffle_seed = 43\n","\n","sample_rate = 16000\n","\n","scale = 0.5\n","\n","batch_size = 128\n","\n","epochs = 15"]},{"cell_type":"markdown","metadata":{},"source":["arrange audio and noise"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.514828Z","iopub.status.busy":"2022-07-24T08:12:14.514385Z","iopub.status.idle":"2022-07-24T08:12:14.773541Z","shell.execute_reply":"2022-07-24T08:12:14.772759Z","shell.execute_reply.started":"2022-07-24T08:12:14.514654Z"},"trusted":true},"outputs":[],"source":["for folder in os.listdir(data_directory):\n","    if os.path.isdir(os.path.join(data_directory, folder)):\n","        if folder in [audio_folder, noise_folder]:\n","            \n","            continue\n","        elif folder in [\"other\", \"_background_noise_\"]:\n","            \n","            shutil.move(\n","                os.path.join(data_directory, folder),\n","                os.path.join(noise_path, folder),\n","            )\n","        else:\n","            shutil.move(\n","                os.path.join(data_directory, folder),\n","                os.path.join(audio_path, folder),\n","            )\n"]},{"cell_type":"markdown","metadata":{},"source":["Get the list of all noise files"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.775331Z","iopub.status.busy":"2022-07-24T08:12:14.775051Z","iopub.status.idle":"2022-07-24T08:12:14.780925Z","shell.execute_reply":"2022-07-24T08:12:14.780226Z","shell.execute_reply.started":"2022-07-24T08:12:14.775292Z"},"trusted":true},"outputs":[],"source":["\n","noise_paths = []\n","for subdir in os.listdir(noise_path):\n","    subdir_path = Path(noise_path) / subdir\n","    if os.path.isdir(subdir_path):\n","        noise_paths += [\n","            os.path.join(subdir_path, filepath)\n","            for filepath in os.listdir(subdir_path)\n","            if filepath.endswith(\".wav\")\n","        ]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.783215Z","iopub.status.busy":"2022-07-24T08:12:14.782568Z","iopub.status.idle":"2022-07-24T08:12:14.795661Z","shell.execute_reply":"2022-07-24T08:12:14.794878Z","shell.execute_reply.started":"2022-07-24T08:12:14.783178Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['speaker-recognition-dataset/16000_pcm_speeches/noise/other/pink_noise.wav',\n"," 'speaker-recognition-dataset/16000_pcm_speeches/noise/other/exercise_bike.wav',\n"," 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/dude_miaowing.wav',\n"," 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/doing_the_dishes.wav',\n"," 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/running_tap.wav',\n"," 'speaker-recognition-dataset/16000_pcm_speeches/noise/_background_noise_/10convert.com_Audience-Claps_daSG5fwdA7o.wav']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["noise_paths"]},{"cell_type":"markdown","metadata":{},"source":["**Split noise into chunks of 16,000 steps each**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.798304Z","iopub.status.busy":"2022-07-24T08:12:14.798024Z","iopub.status.idle":"2022-07-24T08:12:14.804990Z","shell.execute_reply":"2022-07-24T08:12:14.804282Z","shell.execute_reply.started":"2022-07-24T08:12:14.798269Z"},"trusted":true},"outputs":[],"source":["command = (\n","    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n","    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n","    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n","    \"$file | grep sample_rate | cut -f2 -d=`; \"\n","    \"if [ $sample_rate -ne 16000 ]; then \"\n","    \"ffmpeg -hide_banner -loglevel panic -y \"\n","    \"-i $file -ar 16000 temp.wav; \"\n","    \"mv temp.wav $file; \"\n","    \"fi; done; done\"\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:14.808365Z","iopub.status.busy":"2022-07-24T08:12:14.807494Z","iopub.status.idle":"2022-07-24T08:12:18.988865Z","shell.execute_reply":"2022-07-24T08:12:18.987279Z","shell.execute_reply.started":"2022-07-24T08:12:14.808328Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-07-24 08:12:16.365536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:16.485274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:16.486028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:16.489694: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-07-24 08:12:16.490746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:16.491515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:16.492184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:18.573155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:18.574052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:18.574711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-24 08:12:18.575292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["os.system(command)\n","def load_noise_sample(path):\n","    sample, sampling_rate = tf.audio.decode_wav(\n","        tf.io.read_file(path), desired_channels=1\n","    )\n","    if sampling_rate == sample_rate:\n","        slices = int(sample.shape[0] / sample_rate)\n","        sample = tf.split(sample[: slices * sample_rate], slices)\n","        return sample\n","    else:\n","        print(\"Sampling rate for\",path, \"is incorrect\")\n","        return None\n","\n","\n","noises = []\n","for path in noise_paths:\n","    sample = load_noise_sample(path)\n","    if sample:\n","        noises.extend(sample)\n","noises = tf.stack(noises)"]},{"cell_type":"markdown","metadata":{},"source":["**DATASET GENERATION**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:18.990523Z","iopub.status.busy":"2022-07-24T08:12:18.990222Z","iopub.status.idle":"2022-07-24T08:12:18.996561Z","shell.execute_reply":"2022-07-24T08:12:18.995137Z","shell.execute_reply.started":"2022-07-24T08:12:18.990487Z"},"trusted":true},"outputs":[],"source":["def paths_and_labels_to_dataset(audio_paths, labels):\n","    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n","    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n","    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n","    return tf.data.Dataset.zip((audio_ds, label_ds))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:18.998536Z","iopub.status.busy":"2022-07-24T08:12:18.998030Z","iopub.status.idle":"2022-07-24T08:12:19.006524Z","shell.execute_reply":"2022-07-24T08:12:19.005683Z","shell.execute_reply.started":"2022-07-24T08:12:18.998500Z"},"trusted":true},"outputs":[],"source":["def path_to_audio(path):\n","    audio = tf.io.read_file(path)\n","    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n","    return audio"]},{"cell_type":"markdown","metadata":{},"source":["**add noise to dataset**"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.007889Z","iopub.status.busy":"2022-07-24T08:12:19.007544Z","iopub.status.idle":"2022-07-24T08:12:19.017411Z","shell.execute_reply":"2022-07-24T08:12:19.016620Z","shell.execute_reply.started":"2022-07-24T08:12:19.007852Z"},"trusted":true},"outputs":[],"source":["def add_noise(audio, noises=None, scale=0.5):\n","    if noises is not None:\n","        tf_rnd = tf.random.uniform(\n","            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n","        )\n","        noise = tf.gather(noises, tf_rnd, axis=0)\n","\n","        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n","        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n","\n","        audio = audio + noise * prop * scale\n","\n","    return audio"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.018829Z","iopub.status.busy":"2022-07-24T08:12:19.018523Z","iopub.status.idle":"2022-07-24T08:12:19.026997Z","shell.execute_reply":"2022-07-24T08:12:19.026264Z","shell.execute_reply.started":"2022-07-24T08:12:19.018793Z"},"trusted":true},"outputs":[],"source":["def audio_to_fft(audio):\n","    audio = tf.squeeze(audio, axis=-1)\n","    fft = tf.signal.fft(\n","        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n","    )\n","    fft = tf.expand_dims(fft, axis=-1)\n","\n","    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.028556Z","iopub.status.busy":"2022-07-24T08:12:19.028318Z","iopub.status.idle":"2022-07-24T08:12:19.062107Z","shell.execute_reply":"2022-07-24T08:12:19.061452Z","shell.execute_reply.started":"2022-07-24T08:12:19.028520Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['Magaret_Tarcher', 'Benjamin_Netanyau', 'Jens_Stoltenberg', 'Julia_Gillard', 'Nelson_Mandela']\n","Speaker: Magaret_Tarcher\n","Speaker: Benjamin_Netanyau\n","Speaker: Jens_Stoltenberg\n","Speaker: Julia_Gillard\n","Speaker: Nelson_Mandela\n"]}],"source":["\n","class_names = os.listdir(audio_path)\n","print(class_names,)\n","\n","audio_paths = []\n","labels = []\n","for label, name in enumerate(class_names):\n","    print(\"Speaker:\",(name))\n","    dir_path = Path(audio_path) / name\n","    speaker_sample_paths = [\n","        os.path.join(dir_path, filepath)\n","        for filepath in os.listdir(dir_path)\n","        if filepath.endswith(\".wav\")\n","    ]\n","    audio_paths += speaker_sample_paths\n","    labels += [label] * len(speaker_sample_paths)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.063418Z","iopub.status.busy":"2022-07-24T08:12:19.063172Z","iopub.status.idle":"2022-07-24T08:12:19.069765Z","shell.execute_reply":"2022-07-24T08:12:19.069043Z","shell.execute_reply.started":"2022-07-24T08:12:19.063387Z"},"trusted":true},"outputs":[],"source":["# Shuffle to generate random data\n","rng = np.random.RandomState(shuffle_seed)\n","rng.shuffle(audio_paths)\n","rng = np.random.RandomState(shuffle_seed)\n","rng.shuffle(labels)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.071690Z","iopub.status.busy":"2022-07-24T08:12:19.071176Z","iopub.status.idle":"2022-07-24T08:12:19.078503Z","shell.execute_reply":"2022-07-24T08:12:19.077808Z","shell.execute_reply.started":"2022-07-24T08:12:19.071656Z"},"trusted":true},"outputs":[],"source":["# Split into training and validation\n","num_val_samples = int(valid_split * len(audio_paths))\n","train_audio_paths = audio_paths[:-num_val_samples]\n","train_labels = labels[:-num_val_samples]\n","\n","\n","valid_audio_paths = audio_paths[-num_val_samples:]\n","valid_labels = labels[-num_val_samples:]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.080178Z","iopub.status.busy":"2022-07-24T08:12:19.079909Z","iopub.status.idle":"2022-07-24T08:12:19.251603Z","shell.execute_reply":"2022-07-24T08:12:19.250920Z","shell.execute_reply.started":"2022-07-24T08:12:19.080144Z"},"trusted":true},"outputs":[],"source":["# Create datasets, one for training and the other for validation\n","train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n","train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n","    batch_size\n",")\n","\n","valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n","valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"]},{"cell_type":"markdown","metadata":{},"source":["**feature Extraction**"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.253135Z","iopub.status.busy":"2022-07-24T08:12:19.252896Z","iopub.status.idle":"2022-07-24T08:12:19.535814Z","shell.execute_reply":"2022-07-24T08:12:19.535111Z","shell.execute_reply.started":"2022-07-24T08:12:19.253102Z"},"trusted":true},"outputs":[],"source":["# Add noise to the training set\n","train_ds = train_ds.map(\n","    lambda x, y: (add_noise(x, noises, scale=scale), y),\n","    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",")\n","\n","# Transform audio wave to the frequency domain using `audio_to_fft`\n","train_ds = train_ds.map(\n","    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",")\n","\n","train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","valid_ds = valid_ds.map(\n","    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",")\n","valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{},"source":["**Model**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:19.537510Z","iopub.status.busy":"2022-07-24T08:12:19.537250Z","iopub.status.idle":"2022-07-24T08:12:20.602545Z","shell.execute_reply":"2022-07-24T08:12:20.601661Z","shell.execute_reply.started":"2022-07-24T08:12:19.537476Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Conv1D"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:20.604266Z","iopub.status.busy":"2022-07-24T08:12:20.604006Z","iopub.status.idle":"2022-07-24T08:12:20.885822Z","shell.execute_reply":"2022-07-24T08:12:20.885000Z","shell.execute_reply.started":"2022-07-24T08:12:20.604213Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input (InputLayer)              [(None, 8000, 1)]    0                                            \n","__________________________________________________________________________________________________\n","conv1d_15 (Conv1D)              (None, 8000, 128)    512         input[0][0]                      \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 8000, 128)    0           conv1d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_16 (Conv1D)              (None, 8000, 128)    49280       activation_10[0][0]              \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 8000, 128)    0           conv1d_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_17 (Conv1D)              (None, 8000, 128)    49280       activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv1d_14 (Conv1D)              (None, 8000, 128)    256         input[0][0]                      \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 8000, 128)    0           conv1d_17[0][0]                  \n","                                                                 conv1d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 8000, 128)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","max_pooling1d_4 (MaxPooling1D)  (None, 4000, 128)    0           activation_12[0][0]              \n","__________________________________________________________________________________________________\n","average_pooling1d (AveragePooli (None, 1333, 128)    0           max_pooling1d_4[0][0]            \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 170624)       0           average_pooling1d[0][0]          \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 256)          43680000    flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 5)            645         dense_1[0][0]                    \n","==================================================================================================\n","Total params: 43,812,869\n","Trainable params: 43,812,869\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n","    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n","    \n","    for i in range(conv_num - 1):\n","        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n","        x = keras.layers.Activation(activation)(x)\n","    \n","    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n","    x = keras.layers.Add()([x, s])\n","    x = keras.layers.Activation(activation)(x)\n","    \n","    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n","\n","def build_model(input_shape, num_classes):\n","    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n","    \n","    x = residual_block(inputs, 16, 2)\n","    x = residual_block(inputs, 32, 2)\n","    x = residual_block(inputs, 64, 3)\n","    x = residual_block(inputs, 128, 3)\n","    x = residual_block(inputs, 128, 3)\n","    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n","    x = keras.layers.Flatten()(x)\n","    x = keras.layers.Dense(256, activation=\"relu\")(x)\n","    x = keras.layers.Dense(128, activation=\"relu\")(x)\n","    \n","    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n","    \n","    return keras.models.Model(inputs = inputs, outputs = outputs)\n","\n","model = build_model((sample_rate // 2, 1), len(class_names))\n","\n","model.summary()\n","\n","model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n","\n","model_save_filename = \"model.h5\"\n","\n","earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","\n","mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)"]},{"cell_type":"markdown","metadata":{},"source":["**Training**"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:12:20.887363Z","iopub.status.busy":"2022-07-24T08:12:20.887062Z","iopub.status.idle":"2022-07-24T08:30:44.325948Z","shell.execute_reply":"2022-07-24T08:30:44.324977Z","shell.execute_reply.started":"2022-07-24T08:12:20.887324Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n"]},{"name":"stderr","output_type":"stream","text":["2022-07-24 08:12:20.956029: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2022-07-24 08:12:25.120322: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["53/53 [==============================] - 74s 1s/step - loss: 23.9910 - accuracy: 0.6020 - val_loss: 0.3039 - val_accuracy: 0.8813\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.2095 - accuracy: 0.9228 - val_loss: 0.1093 - val_accuracy: 0.9613\n","Epoch 3/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.1170 - accuracy: 0.9575 - val_loss: 0.0883 - val_accuracy: 0.9733\n","Epoch 4/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.1022 - accuracy: 0.9618 - val_loss: 0.1167 - val_accuracy: 0.9613\n","Epoch 5/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.1098 - accuracy: 0.9584 - val_loss: 0.0862 - val_accuracy: 0.9773\n","Epoch 6/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.0809 - accuracy: 0.9726 - val_loss: 0.0840 - val_accuracy: 0.9747\n","Epoch 7/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.0765 - accuracy: 0.9708 - val_loss: 0.0829 - val_accuracy: 0.9747\n","Epoch 8/15\n","53/53 [==============================] - 67s 1s/step - loss: 0.0522 - accuracy: 0.9806 - val_loss: 0.1839 - val_accuracy: 0.9600\n","Epoch 9/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.0606 - accuracy: 0.9773 - val_loss: 0.1232 - val_accuracy: 0.9733\n","Epoch 10/15\n","53/53 [==============================] - 67s 1s/step - loss: 0.0792 - accuracy: 0.9732 - val_loss: 0.0776 - val_accuracy: 0.9773\n","Epoch 11/15\n","53/53 [==============================] - 67s 1s/step - loss: 0.0425 - accuracy: 0.9844 - val_loss: 0.0640 - val_accuracy: 0.9853\n","Epoch 12/15\n","53/53 [==============================] - 67s 1s/step - loss: 0.0367 - accuracy: 0.9871 - val_loss: 0.0687 - val_accuracy: 0.9787\n","Epoch 13/15\n","53/53 [==============================] - 67s 1s/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.0807 - val_accuracy: 0.9773\n","Epoch 14/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.0342 - accuracy: 0.9867 - val_loss: 0.1125 - val_accuracy: 0.9747\n","Epoch 15/15\n","53/53 [==============================] - 68s 1s/step - loss: 0.0372 - accuracy: 0.9846 - val_loss: 0.0914 - val_accuracy: 0.9800\n"]}],"source":["history = model.fit(\n","    train_ds,\n","    epochs=epochs,\n","    validation_data=valid_ds,\n","    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",")"]},{"cell_type":"markdown","metadata":{},"source":["**Accuracy**"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:30:44.343454Z","iopub.status.busy":"2022-07-24T08:30:44.342369Z","iopub.status.idle":"2022-07-24T08:30:54.630984Z","shell.execute_reply":"2022-07-24T08:30:54.629315Z","shell.execute_reply.started":"2022-07-24T08:30:44.343383Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["24/24 [==============================] - 7s 251ms/step - loss: 0.0914 - accuracy: 0.9800\n","Accuracy of model: [0.09138812124729156, 0.9800000190734863]\n"]}],"source":["print(\"Accuracy of model:\",model.evaluate(valid_ds))"]},{"cell_type":"markdown","metadata":{},"source":["**Predict**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-07-24T08:30:54.632980Z","iopub.status.busy":"2022-07-24T08:30:54.632531Z","iopub.status.idle":"2022-07-24T08:30:56.001022Z","shell.execute_reply":"2022-07-24T08:30:56.000275Z","shell.execute_reply.started":"2022-07-24T08:30:54.632939Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n","Welcome\n","The speaker is Julia_Gillard\n","Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n","Welcome\n","The speaker is Magaret_Tarcher\n","Speaker:\u001b[92m Jens_Stoltenberg\u001b[0m\tPredicted:\u001b[92m Jens_Stoltenberg\u001b[0m\n","Welcome\n","The speaker is Jens_Stoltenberg\n","Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n","Welcome\n","The speaker is Nelson_Mandela\n","Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n","Welcome\n","The speaker is Magaret_Tarcher\n","Speaker:\u001b[92m Magaret_Tarcher\u001b[0m\tPredicted:\u001b[92m Magaret_Tarcher\u001b[0m\n","Welcome\n","The speaker is Magaret_Tarcher\n","Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n","Welcome\n","The speaker is Nelson_Mandela\n","Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n","Welcome\n","The speaker is Julia_Gillard\n","Speaker:\u001b[92m Julia_Gillard\u001b[0m\tPredicted:\u001b[92m Julia_Gillard\u001b[0m\n","Welcome\n","The speaker is Julia_Gillard\n","Speaker:\u001b[92m Nelson_Mandela\u001b[0m\tPredicted:\u001b[92m Nelson_Mandela\u001b[0m\n","Welcome\n","The speaker is Nelson_Mandela\n"]}],"source":["SAMPLES_TO_DISPLAY = 10\n","\n","test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n","test_ds = test_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n","    batch_size\n",")\n","\n","test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=scale), y))\n","\n","for audios, labels in test_ds.take(1):\n","    ffts = audio_to_fft(audios)\n","    y_pred = model.predict(ffts)\n","    rnd = np.random.randint(0, batch_size, SAMPLES_TO_DISPLAY)\n","    audios = audios.numpy()[rnd, :, :]\n","    labels = labels.numpy()[rnd]\n","    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n","\n","    for index in range(SAMPLES_TO_DISPLAY):\n","        print(\n","            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n","                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n","                class_names[labels[index]],\n","                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n","                class_names[y_pred[index]],\n","            )\n","        )\n","        if labels[index] ==y_pred[index]:\n","            print(\"Welcome\")\n","        else:\n","            print(\"Sorry\")\n","        print(\"The speaker is\" if labels[index] == y_pred[index] else \"\", class_names[y_pred[index]])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
